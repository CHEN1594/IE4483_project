{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106fe663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 1) Setup & Config =====\n",
    "import os, random, json, math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch import amp\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED)\n",
    "torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "PROJECT_DIR = os.getcwd()\n",
    "OUT_DIR = os.path.join(PROJECT_DIR, \"cifar10_out\"); os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "NUM_WORKERS = 4  # if Windows notebook crashes on test, set to 0 for test loader\n",
    "\n",
    "# toggles\n",
    "USE_MIXUP_CUTMIX = True     # generalization trick (optional)\n",
    "USE_FOCAL_LOSS   = False    # imbalance method 1 (set True to use focal instead of CE)\n",
    "USE_CLASS_WEIGHTS= True     # imbalance method 2 (class-weighted CE or focal weighting)\n",
    "USE_WEIGHTED_SAMPLER = True # imbalance method 3 (resampling minority classes)\n",
    "\n",
    "EPOCHS = 20\n",
    "LR = 3e-4\n",
    "WD = 1e-4\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "488c5b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['airplane',\n",
       " 'automobile',\n",
       " 'bird',\n",
       " 'cat',\n",
       " 'deer',\n",
       " 'dog',\n",
       " 'frog',\n",
       " 'horse',\n",
       " 'ship',\n",
       " 'truck']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===== 2) Data: CIFAR-10 Download + Augmentations =====\n",
    "# We resize CIFAR-10 (32x32) to EfficientNet-B3's expected size ~ 300\n",
    "IMG_SIZE = 96\n",
    "\n",
    "train_tf = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.AutoAugment(policy=transforms.AutoAugmentPolicy.CIFAR10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.4914,0.4822,0.4465), std=(0.2023,0.1994,0.2010)),\n",
    "])\n",
    "\n",
    "test_tf = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.4914,0.4822,0.4465), std=(0.2023,0.1994,0.2010)),\n",
    "])\n",
    "\n",
    "DATA_DIR = os.path.join(PROJECT_DIR, \"datasets_cifar10\")\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "train_set = datasets.CIFAR10(root=DATA_DIR, train=True,  download=True, transform=train_tf)\n",
    "test_set  = datasets.CIFAR10(root=DATA_DIR, train=False, download=True, transform=test_tf)\n",
    "\n",
    "num_classes = 10\n",
    "class_names = train_set.classes  # ['airplane','automobile',...]\n",
    "class_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bf7edfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train counts per class: {6: 5000, 9: 5000, 4: 5000, 1: 5000, 2: 5000, 7: 5000, 8: 5000, 3: 5000, 5: 5000, 0: 5000}\n",
      "Class weights: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# ===== 3) Imbalance utilities =====\n",
    "from collections import Counter\n",
    "import torch.utils.data as tud\n",
    "\n",
    "# Count training samples per class\n",
    "targets = np.array(train_set.targets)\n",
    "counts = Counter(targets.tolist())\n",
    "counts_list = [counts[i] for i in range(num_classes)]\n",
    "print(\"Train counts per class:\", dict(counts))\n",
    "\n",
    "# Class weights = inverse frequency (normalized)\n",
    "inv = 1.0 / (np.array(counts_list) + 1e-8)\n",
    "class_weights = inv / inv.sum() * num_classes\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32, device=DEVICE)\n",
    "print(\"Class weights:\", class_weights)\n",
    "\n",
    "# WeightedRandomSampler (higher prob for minority)\n",
    "if USE_WEIGHTED_SAMPLER:\n",
    "    sample_weights = torch.tensor([1.0 / (counts[t] + 1e-8) for t in targets], dtype=torch.float32)\n",
    "    sampler = tud.WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "    train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, sampler=sampler,\n",
    "                              num_workers=NUM_WORKERS, pin_memory=True)\n",
    "else:\n",
    "    train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                              num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "test_loader  = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f575344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using class-weighted CrossEntropyLoss\n"
     ]
    }
   ],
   "source": [
    "# ===== 4) Model & Loss =====\n",
    "import timm\n",
    "from timm.data import Mixup\n",
    "from timm.loss import SoftTargetCrossEntropy\n",
    "\n",
    "model = timm.create_model('efficientnet_b3', pretrained=True, num_classes=num_classes).to(DEVICE)\n",
    "\n",
    "# Focal loss (simple implementation)\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha  # Tensor of shape [C] or scalar\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "    def forward(self, logits, target):\n",
    "        # logits: [B, C], target: [B] (int64)\n",
    "        ce = nn.functional.cross_entropy(logits, target, weight=self.alpha, reduction='none')\n",
    "        pt = torch.exp(-ce)  # pt = 1 - ce' (approx via CE)\n",
    "        loss = ((1 - pt) ** self.gamma) * ce\n",
    "        if self.reduction == 'mean': return loss.mean()\n",
    "        if self.reduction == 'sum':  return loss.sum()\n",
    "        return loss\n",
    "\n",
    "# Loss selection (class-weighted variants if enabled)\n",
    "if USE_FOCAL_LOSS:\n",
    "    alpha = class_weights_tensor if USE_CLASS_WEIGHTS else None\n",
    "    criterion = FocalLoss(alpha=alpha, gamma=2.0, reduction='mean')\n",
    "    print(\"Using FocalLoss (gamma=2.0)\", \"with class weights\" if USE_CLASS_WEIGHTS else \"\")\n",
    "else:\n",
    "    if USE_CLASS_WEIGHTS:\n",
    "        criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "        print(\"Using class-weighted CrossEntropyLoss\")\n",
    "    else:\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        print(\"Using standard CrossEntropyLoss\")\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WD)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "\n",
    "# Optional Mixup/CutMix\n",
    "mixup_fn = None\n",
    "if USE_MIXUP_CUTMIX:\n",
    "    mixup_fn = Mixup(\n",
    "        mixup_alpha=0.8, cutmix_alpha=1.0, cutmix_minmax=None,\n",
    "        prob=1.0, switch_prob=0.5, mode='batch', label_smoothing=0.0,\n",
    "        num_classes=num_classes\n",
    "    )\n",
    "    soft_criterion = SoftTargetCrossEntropy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26c0525d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|██████████| 391/391 [01:07<00:00,  5.81it/s, loss=0.74] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] loss=0.5230 acc=86.41%\n",
      "==> Saved new best: d:\\A\\IE4483_project\\cifar10_out\\cifar10_efficientnet_b3_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|██████████| 391/391 [01:05<00:00,  5.96it/s, loss=1.62] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] loss=0.4753 acc=91.00%\n",
      "==> Saved new best: d:\\A\\IE4483_project\\cifar10_out\\cifar10_efficientnet_b3_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|██████████| 391/391 [01:05<00:00,  5.95it/s, loss=1.11] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] loss=0.3373 acc=92.51%\n",
      "==> Saved new best: d:\\A\\IE4483_project\\cifar10_out\\cifar10_efficientnet_b3_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|██████████| 391/391 [01:05<00:00,  5.94it/s, loss=1.26] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] loss=0.3797 acc=93.32%\n",
      "==> Saved new best: d:\\A\\IE4483_project\\cifar10_out\\cifar10_efficientnet_b3_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|██████████| 391/391 [01:05<00:00,  5.97it/s, loss=1.09] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] loss=0.3380 acc=93.58%\n",
      "==> Saved new best: d:\\A\\IE4483_project\\cifar10_out\\cifar10_efficientnet_b3_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|██████████| 391/391 [01:05<00:00,  5.96it/s, loss=1.38] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] loss=0.3884 acc=94.13%\n",
      "==> Saved new best: d:\\A\\IE4483_project\\cifar10_out\\cifar10_efficientnet_b3_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|██████████| 391/391 [01:05<00:00,  5.95it/s, loss=1.46] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] loss=0.3562 acc=94.80%\n",
      "==> Saved new best: d:\\A\\IE4483_project\\cifar10_out\\cifar10_efficientnet_b3_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|██████████| 391/391 [01:05<00:00,  5.97it/s, loss=1.17] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] loss=0.3413 acc=95.20%\n",
      "==> Saved new best: d:\\A\\IE4483_project\\cifar10_out\\cifar10_efficientnet_b3_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: 100%|██████████| 391/391 [01:05<00:00,  5.96it/s, loss=1.23] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] loss=0.3237 acc=95.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: 100%|██████████| 391/391 [01:05<00:00,  5.94it/s, loss=1.43] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] loss=0.2944 acc=95.23%\n",
      "==> Saved new best: d:\\A\\IE4483_project\\cifar10_out\\cifar10_efficientnet_b3_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: 100%|██████████| 391/391 [01:05<00:00,  5.95it/s, loss=1.26]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] loss=0.2913 acc=95.51%\n",
      "==> Saved new best: d:\\A\\IE4483_project\\cifar10_out\\cifar10_efficientnet_b3_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: 100%|██████████| 391/391 [01:05<00:00,  5.97it/s, loss=1.39]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] loss=0.2537 acc=95.77%\n",
      "==> Saved new best: d:\\A\\IE4483_project\\cifar10_out\\cifar10_efficientnet_b3_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: 100%|██████████| 391/391 [01:05<00:00,  5.94it/s, loss=0.345]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] loss=0.2317 acc=96.08%\n",
      "==> Saved new best: d:\\A\\IE4483_project\\cifar10_out\\cifar10_efficientnet_b3_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: 100%|██████████| 391/391 [01:05<00:00,  5.97it/s, loss=1.39]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] loss=0.2805 acc=96.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|██████████| 391/391 [01:05<00:00,  5.97it/s, loss=1.29]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] loss=0.3013 acc=96.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: 100%|██████████| 391/391 [01:06<00:00,  5.92it/s, loss=1.25] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] loss=0.2634 acc=96.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: 100%|██████████| 391/391 [01:05<00:00,  5.97it/s, loss=1.15]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] loss=0.2552 acc=96.29%\n",
      "==> Saved new best: d:\\A\\IE4483_project\\cifar10_out\\cifar10_efficientnet_b3_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20: 100%|██████████| 391/391 [01:05<00:00,  5.95it/s, loss=0.985] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] loss=0.2568 acc=96.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20: 100%|██████████| 391/391 [01:05<00:00,  5.97it/s, loss=1.2]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] loss=0.2665 acc=96.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: 100%|██████████| 391/391 [01:05<00:00,  5.94it/s, loss=1.48] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test] loss=0.2733 acc=96.31%\n",
      "==> Saved new best: d:\\A\\IE4483_project\\cifar10_out\\cifar10_efficientnet_b3_best.pt\n",
      "Best Test Acc: 0.9631\n"
     ]
    }
   ],
   "source": [
    "# ===== 5) Train / Evaluate =====\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch import amp\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    correct, total, loss_sum = 0, 0, 0.0\n",
    "    with torch.no_grad(), amp.autocast('cuda', enabled=(DEVICE=='cuda')):\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)   # use hard-label CE for eval\n",
    "            loss_sum += loss.item() * x.size(0)\n",
    "            pred = logits.argmax(1)\n",
    "            correct += (pred == y).sum().item()\n",
    "            total += x.size(0)\n",
    "    return loss_sum/total, correct/total\n",
    "\n",
    "scaler = amp.GradScaler('cuda', enabled=(DEVICE=='cuda'))\n",
    "best_acc = 0.0\n",
    "best_path = os.path.join(OUT_DIR, \"cifar10_efficientnet_b3_best.pt\")\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    model.train()\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch}/{EPOCHS}\")\n",
    "    for x, y in pbar:\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with amp.autocast('cuda', enabled=(DEVICE=='cuda')):\n",
    "            if mixup_fn is not None:\n",
    "                # ✅ pass raw int labels to mixup; it returns soft labels\n",
    "                x, y_soft = mixup_fn(x, y)\n",
    "                logits = model(x)\n",
    "                loss = soft_criterion(logits, y_soft)\n",
    "            else:\n",
    "                logits = model(x)\n",
    "                loss = criterion(logits, y)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        pbar.set_postfix(loss=float(loss.item()))\n",
    "    scheduler.step()\n",
    "\n",
    "    val_loss, val_acc = evaluate(model, test_loader)\n",
    "    print(f\"[Test] loss={val_loss:.4f} acc={val_acc*100:.2f}%\")\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), best_path)\n",
    "        print(\"==> Saved new best:\", best_path)\n",
    "\n",
    "print(\"Best Test Acc:\", best_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10910f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\skyri\\AppData\\Local\\Temp\\ipykernel_5368\\3468400186.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_model.load_state_dict(torch.load(best_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"airplane\": 98.0999984741211,\n",
      "  \"automobile\": 98.0999984741211,\n",
      "  \"bird\": 96.69999694824219,\n",
      "  \"cat\": 90.30000305175781,\n",
      "  \"deer\": 96.20000457763672,\n",
      "  \"dog\": 92.9000015258789,\n",
      "  \"frog\": 98.19999694824219,\n",
      "  \"horse\": 96.9000015258789,\n",
      "  \"ship\": 98.29999542236328,\n",
      "  \"truck\": 97.39999389648438\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# ===== 6) Per-class accuracy & confusion matrix =====\n",
    "import torch\n",
    "\n",
    "def eval_per_class(model, loader, num_classes, names):\n",
    "    model.eval()\n",
    "    correct = torch.zeros(num_classes, dtype=torch.long)\n",
    "    total   = torch.zeros(num_classes, dtype=torch.long)\n",
    "    with torch.no_grad(), amp.autocast('cuda', enabled=(DEVICE=='cuda')):\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "            logits = model(x)\n",
    "            pred = logits.argmax(1)\n",
    "            for c in range(num_classes):\n",
    "                mask = (y==c)\n",
    "                total[c]   += mask.sum().item()\n",
    "                correct[c] += ((pred==c)&mask).sum().item()\n",
    "    acc_pc = (correct.float() / total.clamp(min=1).float()) * 100.0\n",
    "    return {names[i]: float(acc_pc[i].item()) for i in range(num_classes)}\n",
    "\n",
    "best_model = timm.create_model('efficientnet_b3', pretrained=False, num_classes=num_classes).to(DEVICE)\n",
    "best_model.load_state_dict(torch.load(best_path, map_location=DEVICE))\n",
    "per_class = eval_per_class(best_model, test_loader, num_classes, class_names)\n",
    "print(json.dumps(per_class, indent=2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ie4483",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
